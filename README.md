## 游대 Laboratorio Fabric

Este pipeline optimiza la descarga y procesamiento de archivos CSV clim치ticos por a침o, desde el repositorio oficial del Ministerio de Ciencia de Chile.  
Aprovecha el poder de **Spark en Microsoft Fabric** para procesar de forma paralela los archivos.

---

### 丘뙖잺 Estructura del pipeline optimizado

1. **游늽 Notebook `nb_detectar_anios_pendientes`**  
   Detecta a침os disponibles en GitHub y los compara contra carpetas existentes en el Lakehouse. Devuelve un array con los a침os nuevos pendientes por copiar.

2. **游대 Actividad `ForEach` (`ciclo_anios_a_copiar`)**  
   Ejecuta **en paralelo** la copia de archivos por cada a침o nuevo detectado. No espera a que termine una iteraci칩n para iniciar la siguiente.

   > 游눠 Para que el `ForEach` reciba correctamente la salida del notebook como una colecci칩n iterable, es obligatorio:
   >
   > - Que el notebook devuelva un string JSON usando:
   >
   >   ```python
   >   import json
   >   from notebookutils import mssparkutils
   >   mssparkutils.notebook.exit(json.dumps([1950, 1951, 1952]))
   >   ```
   >
   > - Y que la expresi칩n usada como `Items` en el `ForEach` sea:
   >
   >   ```text
   >   @json(activity('nb_detectar_anios_pendientes').output.result.exitValue)
   >   ```
   >
   > Si se omite `@json(...)` o se usa `return` en lugar de `exit()`, Fabric no podr치 iterar sobre los valores, y se mostrar치 el error:
   > `"The function 'length' expects its parameter to be an array or a string"`

3. **游닌 Actividad `Copy Data` (`copy_anio_csv`)**  
   Copia din치micamente el archivo `a침o.csv` desde GitHub al directorio `Files/temperatura_dmc_raw/a침o/`.

4. **游늽 Notebook `nb_crear_tabla_temp_dmc`**  
   Lee todos los archivos CSV desde `temperatura_dmc_flat`, extrae el a침o desde la columna `time`, y registra la tabla Delta `temperatura_dmc`.


## 游빍 Pipeline Completo del Laboratorio

![Pipeline completo](images/pipeline_completo.png)
