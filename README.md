## 游대 Laboratorio Fabric

Este pipeline optimiza la descarga y procesamiento de archivos CSV clim치ticos por a침o, desde el repositorio oficial del Ministerio de Ciencia de Chile. 
Aprovecha el poder de **Spark en Microsoft Fabric** para procesar de forma paralela los archivos.

---

### 丘뙖잺 Estructura del pipeline optimizado

1. **游늽 Notebook `nb_detectar_anios_pendientes`**  
   Detecta a침os disponibles en GitHub y los compara contra carpetas existentes en el Lakehouse. Devuelve un array con los a침os nuevos pendientes por copiar.

2. **游대 Actividad `ForEach` (`ciclo_anios_a_copiar`)**  
   Ejecuta **en paralelo** la copia de archivos por cada a침o nuevo detectado. No espera a que termine una iteraci칩n para iniciar la siguiente.

3. **游닌 Actividad `Copy Data` (`copy_anio_csv`)**  
   Copia din치micamente el archivo `a침o.csv` desde GitHub al directorio `Files/temperatura_dmc_raw/a침o/`.

4. **游늽 Notebook `nb_crear_tabla_temp_dmc`**  
   Lee todos los archivos CSV desde `temperatura_dmc_flat`, extrae el a침o desde la columna `time`, y registra la tabla Delta `temperatura_dmc`.

---

### 游 Punto clave: paso de argumentos desde Notebook a ForEach

Se us칩 la instrucci칩n oficial soportada por Fabric:

```python
from notebookutils import mssparkutils
import json

# Devolver arreglo plano de a침os
mssparkutils.notebook.exit(json.dumps([1950, 1951, 1952]))

